Asymptotic Notations:

1.  We can represent an algorithm with a function F(N). The functions G(N) that gives the upper and lower
    bounds of the F(N) are called its asymptotes.
2.  This G(N) gives the closest bounds to F(N).

*Big O Notation:

1.  The notation that gives the upper bound of a function is called its Big O function.
2.  F(N) = O(G(n)).
3.  Example is F(N) = N^4 + N then G(N) will be N^4.
4.  It also says that there exist a c and a N0 such that  0<=F(N)<=c*G(N) for a certain N>=N0.
5.  The above statement says that F(N) touches/intersect G(N) for a certain N if G(N) is multiplied by a constant c.
6.  Notice that we are interested in a certain large values of N where above condition is satisfied.
7.  Also notice that G(N) could be lower than F(N) at lower values of N but for values bigger than N0, G(N) is always > F(N).
8.  We discard lower order N terms here because thir rate of growth is not significant and does not impact much at
    larger values of N.

Few examples could be:

1.  Upper bound of 3n +8 is 4n because:
    3n + 8 <= 4n for n>=8

2.  Upper bound of N^2 + 1 is 2N^2 for N>=1
    2N^2 >= N^2 + 1
    N^2 >= 1
    N > = 1

3.  Upper bound of 2N^3 - 2N^2
    Because this is substraction
    2N^3 - 2N^2 < = 2N^3 for all N>=1

9.  There is no unique asymptotic bounds. There can be any values of N0 and c that can make a O function.


*Big Omega Notation:

1.  This notation gives the tight lower bound of a function.
2.  This means that the function cannot take value less than the value defined by its Omega at some larger value of N.
3.  So if F(N) = 100N^2 + 10N + 50 then Omega(N^2) is G(N).
4.  This means the big Omega function is N^2 and F(N) can never be lower than G(N).

Few examples could be:
F(N) = 5N^2
0<=cN^2<=5N^2
Omega(N) will be N^2


*Big Theta Notation:


*   Usually we only care about big O of the algorithm because it gives the maximum complexity. we do not care
    much about the big Omega.

*   Asymptotic Analysis of various algorithm statements:

1.  Loops:  




